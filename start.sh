#!/bin/bash

echo "ğŸš€ Starting ByteBot with Local LLM Support..."
echo "=============================================="
echo ""
echo "This will start ByteBot with Ollama for local LLM support."
echo "No API keys required - everything runs locally!"
echo ""

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker first."
    exit 1
fi

# Check if docker-compose is available
if ! command -v docker-compose > /dev/null 2>&1; then
    echo "âŒ docker-compose is not installed. Please install it first."
    exit 1
fi

echo "âœ… Docker is running"
echo "âœ… docker-compose is available"
echo ""

# Start the services
echo "ğŸ³ Starting ByteBot services..."
docker-compose -f docker/docker-compose.yml up -d

echo ""
echo "â³ Waiting for services to start..."
sleep 10

# Check if services are running
echo "ğŸ” Checking service status..."
docker-compose -f docker/docker-compose.yml ps

echo ""
echo "ğŸ‰ ByteBot is starting up!"
echo ""
echo "ğŸ“± Access the application at: http://localhost:9992"
echo "ğŸ–¥ï¸  Desktop view: http://localhost:9992/desktop"
echo "ğŸ¤– Model management: http://localhost:9992/desktop (click 'Local Models')"
echo ""
echo "ğŸ“‹ Next steps:"
echo "1. Open http://localhost:9992 in your browser"
echo "2. Go to Desktop tab â†’ Local Models"
echo "3. Install a model like 'llama3.2:3b'"
echo "4. Create your first task!"
echo ""
echo "ğŸ“š For detailed setup instructions, see LOCAL_LLM_SETUP.md"
echo ""
echo "ğŸ›‘ To stop ByteBot: docker-compose -f docker/docker-compose.yml down"
